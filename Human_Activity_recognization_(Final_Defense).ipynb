{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Human Activity recognization (Final Defense).ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMOCRnY2wkYtt1Us8fx2i7/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Subarna-Liza/Basic-Calculator-Android-2-/blob/main/Human_Activity_recognization_(Final_Defense).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "_sCCg8Jqaj4S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d11b507-d17b-4858-9957-e33b3178972e"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "id": "fbF-D93vYi19"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About kind of folder in my dataset"
      ],
      "metadata": {
        "id": "Arpk0fO1Z6mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path=r\"gdrive/My Drive/Colab Notebooks/Human Activities Recognition\"\n",
        "dataset_folder=os.listdir(dataset_path)\n",
        "print(dataset_folder)\n",
        "print(\"Types of activity found =\",len(dataset_folder))"
      ],
      "metadata": {
        "id": "jjhsZVhiaGxC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50f26076-8b26-4db5-c62d-81ef172e0183"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Playing', 'Quarreling', 'Gossiping', 'Walking', 'Teaching', 'Running', 'Reading', 'Learning']\n",
            "Types of activity found = 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now I take all the images on all the folder in a single list"
      ],
      "metadata": {
        "id": "-xpgykwFd0z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "activities = []\n",
        "\n",
        "for items in dataset_folder:\n",
        "  all_activities = os.listdir('gdrive/My Drive/Colab Notebooks/Human Activities Recognition'+'/'+items)\n",
        "  #print(all_activities)\n",
        "\n",
        "  for activity in all_activities:\n",
        "    activities.append((items,str('gdrive/My Drive/Colab Notebooks/Human Activities Recognition'+ '/'+items) + '/' +activity))\n",
        "    activities\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "8P5W9DR_eBp7"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "activities"
      ],
      "metadata": {
        "id": "lYKt4NKOrAo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd519ab-dd03-4f0c-d4d8-bc289bf12068"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220224_160526.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220224_160529.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220224_160756.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_170557.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_170746.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_170816.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_170818.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_170918.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_170920.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_171001.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_171003.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_171128.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_175448.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_175501.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_175503.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220225_175505.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220110_161125.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_145842.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_145848.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_145850.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_160704.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_161917.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_161934.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_171312.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_171316.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_171502.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_171508.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220112_173222.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6832.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6837.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6842.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6844.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6845.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6847.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6849.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6850.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6851.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6852.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6853.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6854.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6855.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6856.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6857.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6858.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6860.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6861.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6862.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_6863.JPG'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220224_160338.jpg'),\n",
              " ('Playing',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Playing/IMG_20220110_161129.jpg'),\n",
              " ('Quarreling',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Quarreling/IMG_20220110_161336.jpg'),\n",
              " ('Quarreling',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Quarreling/IMG_20220110_161338.jpg'),\n",
              " ('Quarreling',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Quarreling/IMG_20220110_161340.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220224_163707.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220224_163819.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_132919.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_145750.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_145752.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_145801.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_145806.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_145932.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_152038.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_152045.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_152354.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220226_152357.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220301_174630.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301174737.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301174751.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301174803.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301174824.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301174857.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301174957.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301175003.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301175010.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301175454.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301175455.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301175547.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301175548.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301175816.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301180004.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG20220301180037.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220110_160806.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220110_160839.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220110_160925.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220110_160932.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220110_161637.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220110_161639.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220110_161720.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220110_161724.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220112_170816.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163420.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163423.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163433.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163503.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163522.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163556.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163615.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163618.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163814.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163826.jpg'),\n",
              " ('Gossiping',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Gossiping/IMG_20220215_163833.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220226_132814.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220226_132827.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220226_132847.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220226_132906.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220226_132925.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220226_145728.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220226_145746.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220226_145817.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220227_110603.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_170744.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160615.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160718.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160736.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160739.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160836.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160918.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_163027.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_163650.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_163916.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220225_170306.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220225_170311.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220225_170514.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220225_170523.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220225_170543.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160356.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160412.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220110_160228.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220110_160230.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_145243.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_145333.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_145426.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_145433.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_145447.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_162227.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_162236.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_170738.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_170750.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220112_170850.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220212_160514.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220212_160731.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220212_160743.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220212_160805.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220212_180115.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220212_180130.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220212_180138.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160221.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160243.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160254.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160301.jpg'),\n",
              " ('Walking',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Walking/IMG_20220224_160308.jpg'),\n",
              " ('Teaching',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Teaching/FB_IMG_1646151698735.jpg'),\n",
              " ('Teaching',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Teaching/FB_IMG_1646151685377.jpg'),\n",
              " ('Teaching',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Teaching/FB_IMG_1646151692419.jpg'),\n",
              " ('Running',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Running/IMG_20220112_145709.jpg'),\n",
              " ('Running',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Running/IMG_20220112_145710.jpg'),\n",
              " ('Running',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Running/IMG_20220112_145712.jpg'),\n",
              " ('Running',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Running/IMG_20220112_145732.jpg'),\n",
              " ('Running',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Running/IMG_20220112_145801.jpg'),\n",
              " ('Running',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Running/IMG_20220112_145904.jpg'),\n",
              " ('Running',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Running/IMG_20220112_145920.jpg'),\n",
              " ('Running',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Running/IMG_20220112_145922.jpg'),\n",
              " ('Running',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Running/IMG_20220112_171225.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_162117.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_162233.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_162242.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_162838.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_162913.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_163023.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_161251.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_161322.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_161330.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_161552.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_161637.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_161704.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_161710.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_161934.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_161957.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_162043.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_162048.jpg'),\n",
              " ('Reading',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Reading/IMG_20220224_162051.jpg'),\n",
              " ('Learning',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Learning/FB_IMG_1646151623902.jpg'),\n",
              " ('Learning',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Learning/FB_IMG_1646151629740.jpg'),\n",
              " ('Learning',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Learning/FB_IMG_1646151635474.jpg'),\n",
              " ('Learning',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Learning/FB_IMG_1646151685377.jpg'),\n",
              " ('Learning',\n",
              "  'gdrive/My Drive/Colab Notebooks/Human Activities Recognition/Learning/FB_IMG_1646151698735.jpg')]"
            ]
          },
          "metadata": {},
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Create a dataframe"
      ],
      "metadata": {
        "id": "H3HFHe9Cr7GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "activities_df= pd.DataFrame(data=activities,columns=['activity_types','images'])\n",
        "print(activities_df.head())"
      ],
      "metadata": {
        "id": "huHr_wIXbgyF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5b9411-a4e8-4118-e27d-66c88e4e5ad1"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  activity_types                                             images\n",
            "0        Playing  gdrive/My Drive/Colab Notebooks/Human Activiti...\n",
            "1        Playing  gdrive/My Drive/Colab Notebooks/Human Activiti...\n",
            "2        Playing  gdrive/My Drive/Colab Notebooks/Human Activiti...\n",
            "3        Playing  gdrive/My Drive/Colab Notebooks/Human Activiti...\n",
            "4        Playing  gdrive/My Drive/Colab Notebooks/Human Activiti...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Count data in dataset"
      ],
      "metadata": {
        "id": "3K7PPrMZ1erO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Total activities in dataset: \",len(activities_df))\n",
        "activity_types_count=(activities_df['activity_types'].value_counts())\n",
        "print(\"total types of activites= \",activity_types_count)"
      ],
      "metadata": {
        "id": "d4bKm03E1m3l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cb32f77-8b33-4e95-c30c-48280914d426"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total activities in dataset:  186\n",
            "total types of activites=  Playing       50\n",
            "Walking       50\n",
            "Gossiping     48\n",
            "Reading       18\n",
            "Running        9\n",
            "Learning       5\n",
            "Quarreling     3\n",
            "Teaching       3\n",
            "Name: activity_types, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resize the images"
      ],
      "metadata": {
        "id": "kSXuD3p65rcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "path='gdrive/My Drive/Colab Notebooks/Human Activities Recognition/'\n",
        "im_size=224\n",
        "\n",
        "images=[]\n",
        "lebels=[]\n",
        "\n",
        "for i in dataset_folder:\n",
        "  data_path = path + str(i)\n",
        "  filenames = [i for i in os.listdir(data_path)]\n",
        "\n",
        "  for f in filenames:\n",
        "    img = cv2.imread(data_path + '/' +f)\n",
        "    img = cv2.resize(img,(im_size,im_size))\n",
        "\n",
        "    images.append(img)\n",
        "    lebels.append(i)\n"
      ],
      "metadata": {
        "id": "lliKMSC35vn1"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lebels"
      ],
      "metadata": {
        "id": "zHeyTY8P8a7A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "589909fa-a96c-4057-8132-5bca91f2a273"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Playing',\n",
              " 'Quarreling',\n",
              " 'Quarreling',\n",
              " 'Quarreling',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Gossiping',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Walking',\n",
              " 'Teaching',\n",
              " 'Teaching',\n",
              " 'Teaching',\n",
              " 'Running',\n",
              " 'Running',\n",
              " 'Running',\n",
              " 'Running',\n",
              " 'Running',\n",
              " 'Running',\n",
              " 'Running',\n",
              " 'Running',\n",
              " 'Running',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Reading',\n",
              " 'Learning',\n",
              " 'Learning',\n",
              " 'Learning',\n",
              " 'Learning',\n",
              " 'Learning']"
            ]
          },
          "metadata": {},
          "execution_count": 148
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transform the image array to a numpy array"
      ],
      "metadata": {
        "id": "UwARjwl9kD6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "images = np.array(images)\n",
        "images.shape"
      ],
      "metadata": {
        "id": "utH4B4YD72RY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31a70b88-f41a-4fca-9a71-bbc67c4cf531"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(186, 224, 224, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = images.astype('float32')/255"
      ],
      "metadata": {
        "id": "muDRWQMOlosG"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Encoding"
      ],
      "metadata": {
        "id": "aZyVjbaIn_ph"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
        "y = activities_df['activity_types'].values\n",
        "\n",
        "y_labelencoder = LabelEncoder()\n",
        "y = y_labelencoder.fit_transform(y)\n",
        "print(y)\n"
      ],
      "metadata": {
        "id": "6xOlgqHkoHZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6feb3726-8709-479d-dff0-ad7532ffe9d9"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7 7\n",
            " 7 7 7 6 6 6 5 5 5 5 5 5 5 5 5 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 4 1 1 1 1\n",
            " 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=y.reshape(-1,1)\n",
        "onehotencoder = OneHotEncoder()\n",
        "new_y = onehotencoder.fit_transform(y)\n",
        "print(new_y.shape)\n"
      ],
      "metadata": {
        "id": "pGdk-JlepZtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c444a4cc-44c1-4801-d098-796fa0c2e0f2"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(186, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train test split"
      ],
      "metadata": {
        "id": "g-aM3lON5iDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "images,new_y = shuffle(images,new_y,random_state=1)\n",
        "train_x,test_x,train_y,test_y = train_test_split(images,new_y,test_size=0.05,random_state=415)"
      ],
      "metadata": {
        "id": "fPJ_2yvV5o5e"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_x.shape)\n",
        "print(test_x.shape)\n",
        "print(train_y.shape)\n",
        "print(test_y.shape)"
      ],
      "metadata": {
        "id": "hOTY4Hbl7M5q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9bf8a87-a03e-461f-a830-baeebc8e75e4"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(176, 224, 224, 3)\n",
            "(10, 224, 224, 3)\n",
            "(176, 8)\n",
            "(10, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lets starts the algorithm using keras"
      ],
      "metadata": {
        "id": "W6prJzUOmSQD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import necessary libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_files\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "no1AGNh-tmLQ"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "r_wCat3YuJi7"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install activation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rn4tjZqz1H1V",
        "outputId": "0230c7fd-39e9-4fd9-c17c-144569980be4"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: activation in /usr/local/lib/python3.7/dist-packages (0.1.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from activation) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Building model 1 using customized convolutional and pooling layers\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "#input_shape is 100*100 since thats the dimension of each of the human images\n",
        "model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(224,224,3),padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "# specifying parameters for fully connected layer\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(150))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(9,activation = 'softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5zBfZ1yuMkp",
        "outputId": "7bcc3c31-f799-4126-9dcb-289e302212c8"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_24 (Conv2D)          (None, 224, 224, 16)      208       \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 224, 224, 16)      0         \n",
            "                                                                 \n",
            " max_pooling2d_24 (MaxPoolin  (None, 112, 112, 16)     0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_25 (Conv2D)          (None, 112, 112, 32)      2080      \n",
            "                                                                 \n",
            " max_pooling2d_25 (MaxPoolin  (None, 56, 56, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_26 (Conv2D)          (None, 56, 56, 64)        8256      \n",
            "                                                                 \n",
            " max_pooling2d_26 (MaxPoolin  (None, 28, 28, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_27 (Conv2D)          (None, 28, 28, 128)       32896     \n",
            "                                                                 \n",
            " max_pooling2d_27 (MaxPoolin  (None, 14, 14, 128)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 14, 14, 128)       0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 25088)             0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 150)               3763350   \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 150)               0         \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 150)               0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 9)                 1359      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,808,149\n",
            "Trainable params: 3,808,149\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing ootimizers\n",
        "import keras.optimizers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "j9F8ddHxuqVg"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras import activations"
      ],
      "metadata": {
        "id": "MZJHaHT6z5WA"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def identity_block(x, f, filters):\n",
        "\n",
        "  # Retrieve Filters\n",
        "  F1, F2, F3 = filters\n",
        "\n",
        "  x_shortcut = x\n",
        "\n",
        "  #first layer\n",
        "  x= Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(x)\n",
        "  x= BatchNormalization (axis = 3)(x)\n",
        "  x= Activation('relu')(x)\n",
        "\n",
        "\n",
        "  #Second layer\n",
        "  x= Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same')(x)\n",
        "  x= BatchNormalization (axis = 3)(x)\n",
        "  x= Activation('relu')(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  #Third layer\n",
        "  x= Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(x)\n",
        "  x= BatchNormalization (axis = 3)(x)\n",
        "\n",
        "  x= Add() ([x, x_shortcut ])\n",
        "  x= Activation('relu')(x)\n",
        "\n",
        "  return x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def convolutional_block(x, f, filters, s=2):\n",
        "\n",
        "\t# Retrieve Filters\n",
        "\tF1, F2, F3 = filters\n",
        "\n",
        "\tx_shortcut = x\n",
        "\n",
        "\t#first layer\n",
        "\tx= Conv2D( F1, (1,1),strides = (s,s))(x)\n",
        "\n",
        "\tx= BatchNormalization ( axis = 3)(x)\n",
        "\n",
        "\tx= Activation('relu')(x)\n",
        "\n",
        "\n",
        "\t#Second layer\n",
        "\tx= Conv2D(filters = F2, kernel_size = (f, f), strides = (1,1), padding = 'same')(x)\n",
        "\tx= BatchNormalization ( axis = 3)(x)\n",
        "\tx= Activation('relu')(x)\n",
        "\n",
        "\t#Third layer\n",
        "\tx= Conv2D(filters = F1, kernel_size = (1, 1), strides = (1,1), padding = 'valid')(x)\n",
        "\tx= BatchNormalization ( axis = 3)(x)\n",
        "\n",
        "\n",
        "\n",
        "\tx_shortcut = Conv2D(filters=F3, kernel_size = (1,1),  strides =(s,s),padding = 'valid')(x_shortcut)\n",
        "\tx_shortcut = BatchNormalization (axis =3)(x_shortcut )\n",
        "\tx= Add()([x, x_shortcut ])\n",
        "\tx= Activation('relu')(x)\n",
        "\treturn x\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def ResNet50(input_shape =(224, 224, 3),classes=8):\n",
        "\n",
        "\n",
        "\t# Define the input with shape input_shape\n",
        "\tx_input=Input(input_shape)\n",
        "\n",
        "\n",
        "\t#zero_padding \n",
        "\tx=ZeroPadding2D((3,3))(x_input) #3,3 padding\n",
        "\n",
        "\t# stage 1\n",
        "\n",
        "\tx=Conv2D (64,(7,7),strides =(2,2))(x)\n",
        "\tx=BatchNormalization (axis=3)(x)\n",
        "\tx=Activation('relu')(x)\n",
        "\tx=MaxPooling2D ((3,3),strides=(2, 2))(x)\n",
        "\n",
        "\t#stage 2\n",
        "\tx= convolutional_block(x,f=3,filters=[64,64,256],s=1)\n",
        "\n",
        "\tx=identity_block(x, 3,[64,64,256])\n",
        "\tx=identity_block (x, 3, [64, 64, 256])\n",
        "\n",
        "\n",
        "\t#stage 3\n",
        "\tx=convolutional_block(x, f=3, filters =[128,128,512], s=2)\n",
        "\tx=identity_block(x, 3, [128,128,512])\n",
        "\tx=identity_block(x, 3, [128,128,512])\n",
        "\tx=identity_block(x, 3, [128,128,512])\n",
        "\n",
        "\n",
        "\n",
        "\t#stage 4\n",
        "\tx=convolutional_block(x, f=3, filters =[256,256,1024], s=2)\n",
        "\tx=identity_block(x, 3, [256,256,1024])\n",
        "\tx=identity_block(x, 3, [256,256,1024])\n",
        "\tx=identity_block(x, 3, [256,256,1024])\n",
        "\tx=identity_block(x, 3, [256,256,1024])\n",
        "\tx=identity_block(x, 3, [256,256,1024])\n",
        "\n",
        "\n",
        "\t#stage 5\n",
        "\tx=convolutional_block(x, f=3, filters =[512,512,2048], s=2)\n",
        "\tx=identity_block(x, 3, [512,512,2048])\n",
        "\tx=identity_block(x, 3, [512,512,2048])\n",
        "\n",
        "\n",
        "\n",
        "\t#AVGPOOL\n",
        "\tx=AveragePooling2D((2,2),name=\"avg_pool\")(x)\n",
        "\n",
        "\t###End code here###\n",
        "\tx= Flatten()(x)\n",
        "\tx= Dense(classes, activation = 'softmax', name = 'fc' + str(classes),kernel_initializer =glorot_uniform(seed=0))(x)\n",
        "\n",
        "\t#create model\n",
        "\n",
        "\tmodel= Model(inputs = x_input,outputs =x, name='ResNet50')\n",
        "\n",
        "\treturn model"
      ],
      "metadata": {
        "id": "wBTPNxfL8Ily"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6lDcbFGL8b-i"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ResNet50(input_shape = (224, 224, 3), classes =8)\n",
        "\n",
        "optimizer = Adam()\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=optimizer,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "ZL8wfjbK9L1d",
        "outputId": "cea8e56f-5e87-4bec-e0a8-ff476fd61f8e"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-164-e7fdb9c9cdec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m model.compile(loss='categorical_crossentropy',\n\u001b[1;32m      5\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-162-278af6c378e1>\u001b[0m in \u001b[0;36mResNet50\u001b[0;34m(input_shape, classes)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;31m# Define the input with shape input_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mx_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Input' is not defined"
          ]
        }
      ]
    }
  ]
}